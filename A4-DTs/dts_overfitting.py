# -*- coding: utf-8 -*-
"""DTs-Overfitting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i-TCQ38klKp5B70VIQEXcSVWJhLpHK5Y

# Decision Trees: The Overfitting Problem

Decision Trees (DTs) are powerful for classification tasks because they can model complex decision boundaries. However, if a tree grows too deeply, it may overfit by capturing noise in the data rather than general patterns. Overfitting reduces model performance on unseen data.

Let's observe how the performance of a Decision Tree changes as it grows: we will limit the maximum depth of the tree at each iteration.

Let's consider the Breast Cancer dataset from sklearn.
"""

import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import numpy as np

# Load Breast Cancer dataset
# Features represent various cancer attributes; target is benign (0) or malignant (1)
data = load_breast_cancer()
X = pd.DataFrame(data.data, columns=data.feature_names)
y = data.target
# Print feature names and preview dataset
print("Feature Names:")
print(data.feature_names)
print("\nFirst rows of dataset X:")
print(X.head())
print("\nFirst target values y:")
print(y[:5])

def decision_tree_accuracy(max_depth_range):
    # Split data in training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

    # List to save accuracies on training and testing data
    train_accuracies = []
    test_accuracies = []
    total_accuracies = []

    for max_depth in max_depth_range:
        # Create a new DT with different max_depth
        clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)
        clf.fit(X_train, y_train)

        # Calclulate accuracy on training data
        y_train_pred = clf.predict(X_train)
        train_accuracy = accuracy_score(y_train, y_train_pred)
        train_accuracies.append(train_accuracy)

        # Calculate accuracy on testing data
        y_test_pred = clf.predict(X_test)
        test_accuracy = accuracy_score(y_test, y_test_pred)
        test_accuracies.append(test_accuracy)

        # Calculate accuracy on full data
        y_tot_pred = clf.predict(X)
        tot_accuracy = accuracy_score(y, y_tot_pred)
        total_accuracies.append(tot_accuracy)


    # Plot
    plt.figure(figsize=(10, 6))
    plt.plot(max_depth_range, train_accuracies, marker='o', linestyle='-', color='blue', label='Training Accuracy')
    plt.plot(max_depth_range, test_accuracies, marker='o', linestyle='--', color='red', label='Test Accuracy')
    plt.plot(max_depth_range, total_accuracies, marker='o', linestyle='--', color='green', label='Total Accuracy')
    plt.xlabel('Maximum depth (max_depth)')
    plt.ylabel('Accuracy')
    plt.title('DTs accuracy with different max_depth')
    plt.legend()
    plt.grid(True)
    plt.show()

max_depth_values = range(1, 16)
decision_tree_accuracy(max_depth_values)

"""As we can see, the accuracy measured on the test examples initially increases, but then starts to decrease.

As stated in Mitchell's book: “*An hypothesis overfits the training examples if some other hypothesis, which fits the training examples less well, actually performs better over the entire distribution of instances (i.e., including instances beyond the training set).*”

For example, with `max_depth = 8`, the accuracy on training data is 1.0, but the accuracy on the entire distribution of instance is ≈ 0.98. We can say that this hypothesis **overfits** the data, because there is another hypothesis, for example `max_depth = 6`, that performs less well on training data (≈ 0.98), but performs better on the entire distribution of instances (≈ 0.985)

# Solution to Overfitting

There are several approaches to avoiding overfitting in Decision Trees (DT):

- Approaches that stop growing the tree earlier.
- Approaches that allow the tree to overfit the data and then post-prune the tree.

## How to Stop the Growth of the Tree

There are several methods to control the complexity of the tree In `sklearn` there are several methods to control the complexity of a Decision Tree. By using parameters like `min_samples_leaf`, `min_samples_split`, `max_depth`, and `max_leaf_nodes`, we can stop the tree from growing too deep and reduce the risk of overfitting.

### `max_depth`

This parameter limits the maximum depth of the tree. A shallower tree reduces the risk of overfitting but might have lower accuracy on the training set.

For example, setting `max_depth=4` ensures that the tree will not grow deeper than 4 levels, preventing overfitting but potentially reducing the model's ability to correctly classify the training data.

### `min_samples_leaf`

This parameter sets the minimum number of samples required to be in a leaf node. Increasing this value can help prevent the creation of trees that overfit the training data.

For example, setting `min_samples_leaf=5` ensures that no leaf node will have fewer than 5 samples, reducing overfitting by forcing the tree to generalize better.


### `min_samples_split` & `max_leaf_nodes`
`min_samples_split` determines the minimum number of samples required to split an internal node, `max_leaf_nodes` determines the limit on the number of leaf nodes of the tree.
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Accuracy results for training and testing data
train_accuracies = []
test_accuracies = []

# Varying min_samples_leaf parameter
min_samples_leaf_range = range(1, 21)

for min_samples_leaf in min_samples_leaf_range:
    clf = DecisionTreeClassifier(min_samples_leaf=min_samples_leaf, random_state=42)
    clf.fit(X_train, y_train)

    # Calculate accuracy on training and testing data
    train_acc = accuracy_score(y_train, clf.predict(X_train))
    test_acc = accuracy_score(y_test, clf.predict(X_test))

    train_accuracies.append(train_acc)
    test_accuracies.append(test_acc)

# Plot accuracy results for min_samples_leaf
plt.figure(figsize=(14, 6))
plt.subplot(1, 2, 1)
plt.plot(min_samples_leaf_range, train_accuracies, label='Training Accuracy', color='blue', marker='o')
plt.plot(min_samples_leaf_range, test_accuracies, label='Testing Accuracy', color='red', marker='o')
plt.title('Accuracy vs. min_samples_leaf')
plt.xlabel('min_samples_leaf')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

# Varying min_samples_split parameter
min_samples_split_range = range(2, 21)
train_accuracies = []
test_accuracies = []

for min_samples_split in min_samples_split_range:
    clf = DecisionTreeClassifier(min_samples_split=min_samples_split, random_state=42)
    clf.fit(X_train, y_train)

    # Calculate accuracy on training and testing data
    train_acc = accuracy_score(y_train, clf.predict(X_train))
    test_acc = accuracy_score(y_test, clf.predict(X_test))

    train_accuracies.append(train_acc)
    test_accuracies.append(test_acc)

# Plot accuracy results for min_samples_split
plt.subplot(1, 2, 2)
plt.plot(min_samples_split_range, train_accuracies, label='Training Accuracy', color='blue', marker='o')
plt.plot(min_samples_split_range, test_accuracies, label='Testing Accuracy', color='red', marker='o')
plt.title('Accuracy vs. min_samples_split')
plt.xlabel('min_samples_split')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

"""As we can see, the accuracy on the test data varies with different values of the `min_samples_leaf` and `min_samples_split` parameters.

"""

# Best results
best_accuracy = 0
best_params = {'max_depth': None, 'min_samples_leaf': None}

# max_depth and min_samples_leaf parameters
max_depth_range = range(1, 10)
min_samples_leaf_range = range(1, 21)

# Accuracy results of each combination
accuracies = []

for max_depth in max_depth_range:
    for min_samples_leaf in min_samples_leaf_range:
        clf = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=42)
        clf.fit(X_train, y_train)
        test_acc = accuracy_score(y_test, clf.predict(X_test))
        accuracies.append((max_depth, min_samples_leaf, test_acc))

        # Update best parameters
        if test_acc > best_accuracy:
            best_accuracy = test_acc
            best_params = {'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf}

# Accuracies to NumPy array for plotting
accuracies = np.array(accuracies)
max_depth_values = accuracies[:, 0]
min_samples_leaf_values = accuracies[:, 1]
test_accuracies = accuracies[:, 2]

# Plot
plt.figure(figsize=(10, 6))
sc = plt.scatter(max_depth_values, min_samples_leaf_values, c=test_accuracies, cmap='summer_r')
plt.colorbar(sc, label='Accuracy on Testing Set')
plt.xlabel('max_depth')
plt.ylabel('min_samples_leaf')
plt.title('Accuracy with Different max_depth & min_samples_leaf')
plt.show()

# Best parameters and accuracy
print(f"Best parameters: {best_params}")
print(f"Accuracy on testing data: {best_accuracy:.4f}")

# Best results
best_accuracy = 0
best_params = {'max_depth': None, 'min_samples_split': None}

# max_depth and min_samples_leaf parameters
max_depth_range = range(1, 10)
min_samples_split_range = range(2, 21)

# Accuracy results of each combination
accuracies = []

for max_depth in max_depth_range:
    for min_samples_split in min_samples_split_range:
        clf = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split, random_state=42)
        clf.fit(X_train, y_train)
        test_acc = accuracy_score(y_test, clf.predict(X_test))
        accuracies.append((max_depth, min_samples_split, test_acc))

        # Update best parameters
        if test_acc > best_accuracy:
            best_accuracy = test_acc
            best_params = {'max_depth': max_depth, 'min_samples_split': min_samples_split}

# Accuracies to NumPy array for plotting
accuracies = np.array(accuracies)
max_depth_values = accuracies[:, 0]
min_samples_split_values = accuracies[:, 1]
test_accuracies = accuracies[:, 2]

# Plot
plt.figure(figsize=(10, 6))
sc = plt.scatter(max_depth_values, min_samples_split_values, c=test_accuracies, cmap='summer_r')
plt.colorbar(sc, label='Accuracy on Testing Set')
plt.xlabel('max_depth')
plt.ylabel('min_samples_split')
plt.title('Accuracy with Different max_depth & min_samples_split')
plt.show()

# Best parameters and accuracy
print(f"Best parameters: {best_params}")
print(f"Accuracy on testing data: {best_accuracy:.4f}")

"""## Feature work

Future work for this activity could be to analyze how post-pruning works in Scikit-Learn. Although sklearn does not directly support traditional post-pruning for Decision Trees, it provides a way to simulate similar behavior using the `ccp_alpha` parameter, which stands for Cost Complexity Pruning Alpha. An [overview](https://scikit-learn.org/1.5/auto_examples/tree/plot_cost_complexity_pruning.html) is available on sklearn official documentation.

## Sources
- *Machine Learning, Tom Mitchell (1997)*
- [sklearn](https://scikit-learn.org/stable/auto_examples/tree/index.html)
"""